{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27719223",
   "metadata": {},
   "source": [
    "\n",
    "# Trabajo Práctico 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d011d",
   "metadata": {},
   "source": [
    "\n",
    "Descargar el dataset **Facebook comment volume** https://archive.ics.uci.edu/ml/datasets/Facebook+Comment+Volume+Dataset. \n",
    "\n",
    "El dataset tiene diferentes versiones, utilizaremos la **número 5** para train y para test **Features_TestSet**. \n",
    "\n",
    "Notar que trae **carpeta de train y de test**. \n",
    "\n",
    "Una descripcióm completa del dataset pueden encontrarla en el link. Se trata de publicaciones de Facebook y se quiere **predecir la columna 54: cantidad de comentarios en las próximas H horas\"**.\n",
    "\n",
    "El dataset contiene variables en muchos formatos diferentes, algunos de los cuales no hemos trabajado o no lo hemos hechos en profundidad. Esas variables pueden ser descartadas o bien hacer una investigación personal para ver de qué manera poder incluirlas para mejorar los resultados obtenidos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9fc6f",
   "metadata": {},
   "source": [
    "## Notas santi\n",
    "\n",
    "The task here is to estimate the comment count that a post is expected to receive in next few hours.\n",
    "La unidad basica es el post. Total posts: 51108. De los que quedan 80% en train (40998). y 20% en test (10120).\n",
    "\n",
    "Target value: Comentarios que recibe el post. \n",
    "NOTE: Given some posts that appeared in past, whose target values (comments received) are already known, we simulated the scenario.\n",
    "\n",
    "Los autores lo consideran un problema de regresion (porque se estima un valor numerico que es el comment count)\n",
    "\n",
    "### Respecto al tiempo. \n",
    "\n",
    "Base date/time. El autor establece una hora y una fecha como BD/T arbitrariamente. Y luego toma los comentarios que ocurrieron los ultimos tres dias. Filtra un par. Y luego se queda con un total de posts de 51108. Este es el data set completo antes del split. \n",
    "\n",
    "Luego el split de train y testing se hace en base al tiempo. Se selecciona arbitrariamente una fecha/hora y lo que esta antes es de train (el pasado), y lo que esta despues es de test(el futuro)\n",
    "\n",
    "\n",
    "It is selected to simulate the scenario, as we already know what will happen after this. There is one more kind of time we used in this formulation: is the post published time, which comes before the selected base date/time.\n",
    "\n",
    "Primero parte el D-S en dos definiendo una linea de corte temporal arbitraria. Esto hace que el set se divida en 80 por ciento de post mas veijos que la linea de corte, y 20 porciento mas nuevos que la linea de corte. \n",
    "\n",
    "Una vez dividido en test y train, establece *variantes* para cada uno. el proceso de gerneracion de variantes en distinto en train y en test. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Features\n",
    "53 en total + el target value para cada **post** \n",
    "\n",
    "- 4 features meta de la pagina en donde esta el post. Page likes, Page Category, Page Checkin's, Page Talking About.\n",
    "\n",
    "- 5 esenciales primarias que representan cantidad de comentarios para distintos tiempos en relacion al base date/time.  La cantidad de comentarios se hace *para atras*, es decir una vez que defino el base date time, cuento para atras cuantos comentarios hubo. en distintos intervalos\n",
    "\n",
    "C1. Cantidad total de comentarios antes del basedatetime seleccionado. Se define 72hs no se porque. \n",
    "C2. cantidad de comentarios 24 hs antes del selected BDT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a976dd3",
   "metadata": {},
   "source": [
    "# Importar librerías\n",
    "\n",
    "Importar aquellas librerías que serán utilizadas en el trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845b6c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954111ce",
   "metadata": {},
   "source": [
    "# Cargar datos\n",
    "Cargar los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26f41c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40948, 54) (81311, 54) (121097, 54) (160423, 54) (199029, 54)\n",
      "False False False False False\n"
     ]
    }
   ],
   "source": [
    "X_var1 = pd.read_csv(\"Dataset/Training/Features_Variant_1.csv\")\n",
    "X_var2 = pd.read_csv(\"Dataset/Training/Features_Variant_2.csv\")\n",
    "X_var3 = pd.read_csv(\"Dataset/Training/Features_Variant_3.csv\")\n",
    "X_var4 = pd.read_csv(\"Dataset/Training/Features_Variant_4.csv\")\n",
    "X_var5 = pd.read_csv(\"Dataset/Training/Features_Variant_5.csv\")\n",
    "\n",
    "X_var1.columns = ['Page Popularity/likes', 'Page Checkins', 'Page talking about ', 'Page Category ', 'Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV', 'CMNTS C1','CMNTS C2','CMNTS C3','CMNTS C4','CMNTS C5','BASE TIME', 'Post length', 'Post Share Count','Post Promotion Status ',' hrs for which we have the target variable/ comments received.  ','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','TARGET VALUE IN NEYT H HOURS']\n",
    "X_var2.columns = ['Page Popularity/likes', 'Page Checkins', 'Page talking about ', 'Page Category ', 'Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV', 'CMNTS C1','CMNTS C2','CMNTS C3','CMNTS C4','CMNTS C5','BASE TIME', 'Post length', 'Post Share Count','Post Promotion Status ',' hrs for which we have the target variable/ comments received.  ','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','TARGET VALUE IN NEXT H HOURS']\n",
    "X_var3.columns = ['Page Popularity/likes', 'Page Checkins', 'Page talking about ', 'Page Category ', 'Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV', 'CMNTS C1','CMNTS C2','CMNTS C3','CMNTS C4','CMNTS C5','BASE TIME', 'Post length', 'Post Share Count','Post Promotion Status ',' hrs for which we have the target variable/ comments received.  ','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','TARGET VALUE IN NEXT H HOURS']\n",
    "X_var4.columns = ['Page Popularity/likes', 'Page Checkins', 'Page talking about ', 'Page Category ', 'Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV', 'CMNTS C1','CMNTS C2','CMNTS C3','CMNTS C4','CMNTS C5','BASE TIME', 'Post length', 'Post Share Count','Post Promotion Status ',' hrs for which we have the target variable/ comments received.  ','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','TARGET VALUE IN NEXT H HOURS']\n",
    "X_var5.columns = ['Page Popularity/likes', 'Page Checkins', 'Page talking about ', 'Page Category ', 'Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV','Essential DRV', 'CMNTS C1','CMNTS C2','CMNTS C3','CMNTS C4','CMNTS C5','BASE TIME', 'Post length', 'Post Share Count','Post Promotion Status ',' hrs for which we have the target variable/ comments received.  ','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','PUBlished Weekdays (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','BDT weekday (bin)','TARGET VALUE IN NEXT H HOURS']\n",
    "\n",
    "print(X_var1.shape,X_var2.shape,X_var3.shape,X_var4.shape,X_var5.shape )\n",
    "\n",
    "#autor dice que esta todo ok, pero voy a chequear si hay NaNs\n",
    "print(X_var1.isnull().values.any(),X_var2.isnull().values.any(),X_var3.isnull().values.any(),X_var4.isnull().values.any(),X_var5.isnull().values.any(), )\n",
    "\n",
    "# Ningun data set tiene Nans. todos los datasets tienen misma cantidad de features. Digo que es tidy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2eecaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10043, 54)\n"
     ]
    }
   ],
   "source": [
    "Y_test_set = pd.read_csv(\"Dataset/Testing/Features_TestSet.csv\")\n",
    "Y_case1\n",
    "\n",
    "print(Y_test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93000bd",
   "metadata": {},
   "source": [
    "# Análisis exploratorio básico y preprocesamiento de los datos\n",
    "\n",
    "Análisis de los datos para conocer los mismos, ver datos faltantes, decidir cómo tratarlos, ver distribuciones, relaciones, etc. Procesar los datos centrándolos, reescalando, codificando, reduciendo dimensiones, etc. según considere necesario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66211cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13e49832",
   "metadata": {},
   "source": [
    "# Modelos y evaluación\n",
    "Probar diferentes modelos para predecir la variable objetivo. Calcular las métricas que considere relevantes. Comentar los resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529db73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('FIUBA001')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c28c3cf458679f9b83f61209d65f8a8f2d99f99372cb71f1948565dfdc4b7b2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
